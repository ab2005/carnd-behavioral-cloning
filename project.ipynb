{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Deep Learning to Clone Driving Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission criterias\n",
    "\n",
    "### Quality of Code\n",
    "- Is the code functional?\n",
    "    - TODO The model provided can be used to successfully operate the simulation.\n",
    "- Is the code usable and readable?\n",
    "    - TODO The code in model.py uses a Python generator, if needed, to generate data for training rather than storing the training data in memory. \n",
    "    - TODO: The model.py code is clearly organized and comments are included where needed.\n",
    "    \n",
    "### Model Architecture and Training Strategy\n",
    "- Has an appropriate model architecture been employed for the task?\n",
    "    * TODO: The neural network uses convolution layers with appropriate filter sizes. \n",
    "    * TODO: Layers exist to introduce nonlinearity into the model. \n",
    "    * TODO: The data is normalized in the model.\n",
    "    \n",
    "- Has an attempt been made to reduce overfitting of the model?\n",
    "    - TODO: Train/validation/test splits have been used, and the model uses dropout layers or other methods to reduce overfitting.\n",
    "- Have the model parameters been tuned appropriately?\n",
    "    - TODO: Learning rate parameters are chosen with explanation, or an Adam optimizer is used.\n",
    "- Is the training data chosen appropriately?\n",
    "    - TODO: Training data has been chosen to induce the desired behavior in the simulation (i.e. keeping the car on the track).\n",
    "    \n",
    "### Architecture and Training Documentation\n",
    "- Is the solution design documented?\n",
    "    - The README thoroughly discusses the approach taken for deriving and designing a model architecture fit for solving the given problem.\n",
    "- Is the model architecture documented?\n",
    "    - The README provides sufficient details of the characteristics and qualities of the architecture, such as the type of model used, the number of layers, the size of each layer. Visualizations emphasizing particular qualities of the architecture are encouraged.\n",
    "- Is the creation of the training dataset and training process documented?\n",
    "    - The README describes how the model was trained and what the characteristics of the dataset are. Information such as how the dataset was generated and examples of images from the dataset should be included.\n",
    "    \n",
    "### Simulation\n",
    "- Is the car able to navigate correctly on test data?\n",
    "    - No tire may leave the drivable portion of the track surface. The car may not pop up onto ledges or roll over any surfaces that would otherwise be considered unsafe (if humans were in the vehicle)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The list of file to submit:\n",
    "- model.py - The script used to create and train the model.\n",
    "- [drive.py](./drive.py) - The script to drive the car. You can feel free to resubmit the original drive.py or make modifications and submit your modified version.\n",
    "- model.json - The model architecture.\n",
    "- model.h5 - The model weights.\n",
    "- [README.md](./README.md) - explains the structure of your network and training approach. While we recommend using English for good practice, writing in any language is acceptable (reviewers will translate). There is no minimum word count so long as there are complete descriptions of the problems and the strategies. See the rubric for more details about the expectations.\n",
    "\n",
    "## 1. Files in this repo\n",
    "* `model.py`: Python script to import data, train model and save model.\n",
    "* `model.json`: Model architecture.\n",
    "* `model.h5`: Model weights (Large file, > 300MB).\n",
    "* `drive.py`: Python script that tells the car in the simulator how to drive\n",
    "* `data/`: file with training data\n",
    "    * Attributes such as 'steering angle' mapped to image paths in `driving_log.csv`.\n",
    "    * Images in `IMG/`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Objective to building model\n",
    "The goal is the car to drive within the lane lines, so the model needs to recognise lane lines from the camera images.\n",
    "TODO: Copy the Nvidia pipeline. It works :) And it's not too complex.\n",
    "\n",
    "### Preprocessing\n",
    "Re-size the input image. I was able to size the image down by 2, reducing the number of pixels by 4. This really helped speed up model training and did not seem to impact the accuracy.\n",
    "\n",
    "### Warning!\n",
    "drive.py sends RGB images to the model; cv2.imread() reads images in BGR format!!!!\n",
    "Fixed the bug and passed the 2 sharp corners at the first attempt lol.\n",
    "\n",
    "\n",
    "### Starting out\n",
    "\n",
    "##### Train 3 images \n",
    "When you're starting out, pick three images from the .csv file, one with negative steering, one with straight, and one with right steering. Train a model with just those three images and see if you can get it to predict them correctly. This will tell you that your model is good and your turn-around time will be very quick. Then you can start adding more training data\n",
    "\n",
    "##### Train on provided data \n",
    "There is 8000 images provided in the training set. Use it to train the network. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out [Comma.ai model](https://github.com/commaai/research/blob/master/train_steering_model.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/commaai/research/blob/master/train_steering_model.py\n",
    "\"\"\"\n",
    "Steering angle prediction model\n",
    "\"\"\"\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, ELU\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "\n",
    "from server import client_generator\n",
    "\n",
    "\n",
    "def gen(hwm, host, port):\n",
    "  for tup in client_generator(hwm=hwm, host=host, port=port):\n",
    "    X, Y, _ = tup\n",
    "    Y = Y[:, -1]\n",
    "    if X.shape[1] == 1:  # no temporal context\n",
    "      X = X[:, -1]\n",
    "    yield X, Y\n",
    "\n",
    "\n",
    "def get_model(time_len=1):\n",
    "  ch, row, col = 3, 160, 320  # camera format\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "            input_shape=(ch, row, col),\n",
    "            output_shape=(ch, row, col)))\n",
    "  model.add(Convolution2D(16, 8, 8, subsample=(4, 4), border_mode=\"same\"))\n",
    "  model.add(ELU())\n",
    "  model.add(Convolution2D(32, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "  model.add(ELU())\n",
    "  model.add(Convolution2D(64, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dropout(.2))\n",
    "  model.add(ELU())\n",
    "  model.add(Dense(512))\n",
    "  model.add(Dropout(.5))\n",
    "  model.add(ELU())\n",
    "  model.add(Dense(1))\n",
    "\n",
    "  model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  parser = argparse.ArgumentParser(description='Steering angle model trainer')\n",
    "  parser.add_argument('--host', type=str, default=\"localhost\", help='Data server ip address.')\n",
    "  parser.add_argument('--port', type=int, default=5557, help='Port of server.')\n",
    "  parser.add_argument('--val_port', type=int, default=5556, help='Port of server for validation dataset.')\n",
    "  parser.add_argument('--batch', type=int, default=64, help='Batch size.')\n",
    "  parser.add_argument('--epoch', type=int, default=200, help='Number of epochs.')\n",
    "  parser.add_argument('--epochsize', type=int, default=10000, help='How many frames per epoch.')\n",
    "  parser.add_argument('--skipvalidate', dest='skipvalidate', action='store_true', help='Multiple path output.')\n",
    "  parser.set_defaults(skipvalidate=False)\n",
    "  parser.set_defaults(loadweights=False)\n",
    "  args = parser.parse_args()\n",
    "\n",
    "  model = get_model()\n",
    "  model.fit_generator(\n",
    "    gen(20, args.host, port=args.port),\n",
    "    samples_per_epoch=10000,\n",
    "    nb_epoch=args.epoch,\n",
    "    validation_data=gen(20, args.host, port=args.val_port),\n",
    "    nb_val_samples=1000\n",
    "  )\n",
    "  print(\"Saving model weights and configuration file.\")\n",
    "\n",
    "  if not os.path.exists(\"./outputs/steering_model\"):\n",
    "      os.makedirs(\"./outputs/steering_model\")\n",
    "\n",
    "  model.save_weights(\"./outputs/steering_model/steering_angle.keras\", True)\n",
    "  with open('./outputs/steering_model/steering_angle.json', 'w') as outfile:\n",
    "    json.dump(model.to_json(), outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try [NVIDIA model](https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/) \n",
    "Here is [complete explanation](https://chatbotslife.com/learning-human-driving-behavior-using-nvidias-neural-network-model-and-image-augmentation-80399360efee#.l03zgi3tn) of the solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'load_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e3972c44e8d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCSVLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mload_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_data_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_data_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_train_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'load_data'"
     ]
    }
   ],
   "source": [
    "# NVIDIA model\n",
    "import cv2\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Flatten, Dense, Dropout, ELU, Lambda\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "\n",
    "NVIDIA_H, NVIDIA_W = 66, 200\n",
    "\n",
    "CONFIG = {\n",
    "    'batchsize': 512,\n",
    "    'input_width': NVIDIA_W,\n",
    "    'input_height': NVIDIA_H,\n",
    "    'input_channels': 3,\n",
    "    'delta_correction': 0.25,\n",
    "    'augmentation_steer_sigma': 0.2,\n",
    "    'augmentation_value_min': 0.2,\n",
    "    'augmentation_value_max': 1.5,\n",
    "    'bias': 0.8,\n",
    "    'crop_height': range(20, 140)\n",
    "}\n",
    "\n",
    "def preprocess(frame_bgr, verbose=False):\n",
    "    # set training images resized shape\n",
    "    h, w = CONFIG['input_height'], CONFIG['input_width']\n",
    "\n",
    "    # crop image (remove useless information)\n",
    "    frame_cropped = frame_bgr[CONFIG['crop_height'], :, :]\n",
    "\n",
    "    # resize image\n",
    "    frame_resized = cv2.resize(frame_cropped, dsize=(w, h))\n",
    "\n",
    "    # eventually change color space\n",
    "    if CONFIG['input_channels'] == 1:\n",
    "        frame_resized = np.expand_dims(cv2.cvtColor(frame_resized, cv2.COLOR_BGR2YUV)[:, :, 0], 2)\n",
    "\n",
    "    if verbose:\n",
    "        plt.figure(1), plt.imshow(cv2.cvtColor(frame_bgr, code=cv2.COLOR_BGR2RGB))\n",
    "        plt.figure(2), plt.imshow(cv2.cvtColor(frame_cropped, code=cv2.COLOR_BGR2RGB))\n",
    "        plt.figure(3), plt.imshow(cv2.cvtColor(frame_resized, code=cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "\n",
    "    return frame_resized.astype('float32')\n",
    "\n",
    "\n",
    "def load_data_batch(data, batchsize=CONFIG['batchsize'], data_dir='data', augment_data=True, bias=0.5):\n",
    "    # set training images resized shape\n",
    "    h, w, c = CONFIG['input_height'], CONFIG['input_width'], CONFIG['input_channels']\n",
    "\n",
    "    # prepare output structures\n",
    "    X = np.zeros(shape=(batchsize, h, w, c), dtype=np.float32)\n",
    "    y_steer = np.zeros(shape=(batchsize,), dtype=np.float32)\n",
    "    y_throttle = np.zeros(shape=(batchsize,), dtype=np.float32)\n",
    "\n",
    "    # shuffle data\n",
    "    shuffled_data = shuffle(data)\n",
    "\n",
    "    loaded_elements = 0\n",
    "    while loaded_elements < batchsize:\n",
    "\n",
    "        ct_path, lt_path, rt_path, steer, throttle, brake, speed = shuffled_data.pop()\n",
    "\n",
    "        # cast strings to float32\n",
    "        steer = np.float32(steer)\n",
    "        throttle = np.float32(throttle)\n",
    "\n",
    "        # randomly choose which camera to use among (central, left, right)\n",
    "        # in case the chosen camera is not the frontal one, adjust steer accordingly\n",
    "        delta_correction = CONFIG['delta_correction']\n",
    "        camera = random.choice(['frontal', 'left', 'right'])\n",
    "        if camera == 'frontal':\n",
    "            frame = preprocess(cv2.imread(join(data_dir, ct_path.strip())))\n",
    "            steer = steer\n",
    "        elif camera == 'left':\n",
    "            frame = preprocess(cv2.imread(join(data_dir, lt_path.strip())))\n",
    "            steer = steer + delta_correction\n",
    "        elif camera == 'right':\n",
    "            frame = preprocess(cv2.imread(join(data_dir, rt_path.strip())))\n",
    "            steer = steer - delta_correction\n",
    "\n",
    "        if augment_data:\n",
    "            # mirror images with chance=0.5\n",
    "            if random.choice([True, False]):\n",
    "                frame = frame[:, ::-1, :]\n",
    "                steer *= -1.\n",
    "            # perturb slightly steering direction\n",
    "            steer += np.random.normal(loc=0, scale=CONFIG['augmentation_steer_sigma'])\n",
    "            # if color images, randomly change brightness\n",
    "            if CONFIG['input_channels'] == 3:\n",
    "                frame = cv2.cvtColor(frame, code=cv2.COLOR_BGR2HSV)\n",
    "                frame[:, :, 2] *= random.uniform(CONFIG['augmentation_value_min'], CONFIG['augmentation_value_max'])\n",
    "                frame[:, :, 2] = np.clip(frame[:, :, 2], a_min=0, a_max=255)\n",
    "                frame = cv2.cvtColor(frame, code=cv2.COLOR_HSV2BGR)\n",
    "        # check that each element in the batch meet the condition\n",
    "        steer_magnitude_thresh = np.random.rand()\n",
    "        if (abs(steer) + bias) < steer_magnitude_thresh:\n",
    "            pass  # discard this element\n",
    "        else:\n",
    "            X[loaded_elements] = frame\n",
    "            y_steer[loaded_elements] = steer\n",
    "            loaded_elements += 1\n",
    "\n",
    "    if K.backend() == 'theano':\n",
    "        X = X.transpose(0, 3, 1, 2)\n",
    "\n",
    "    return X, y_steer\n",
    "\n",
    "\n",
    "def generate_data_batch(data, batchsize=CONFIG['batchsize'], data_dir='data', augment_data=True, bias=0.5):\n",
    "    # set training images resized shape\n",
    "    h, w, c = CONFIG['input_height'], CONFIG['input_width'], CONFIG['input_channels']\n",
    "\n",
    "    while True:\n",
    "        # prepare output structures\n",
    "        X = np.zeros(shape=(batchsize, h, w, c), dtype=np.float32)\n",
    "        y_steer = np.zeros(shape=(batchsize,), dtype=np.float32)\n",
    "        y_throttle = np.zeros(shape=(batchsize,), dtype=np.float32)\n",
    "\n",
    "        # shuffle data\n",
    "        shuffled_data = shuffle(data)\n",
    "\n",
    "        loaded_elements = 0\n",
    "        while loaded_elements < batchsize:\n",
    "\n",
    "            ct_path, lt_path, rt_path, steer, throttle, brake, speed = shuffled_data.pop()\n",
    "\n",
    "            # cast strings to float32\n",
    "            steer = np.float32(steer)\n",
    "            throttle = np.float32(throttle)\n",
    "\n",
    "            # randomly choose which camera to use among (central, left, right)\n",
    "            # in case the chosen camera is not the frontal one, adjust steer accordingly\n",
    "            delta_correction = CONFIG['delta_correction']\n",
    "            camera = random.choice(['frontal', 'left', 'right'])\n",
    "            if camera == 'frontal':\n",
    "                frame = preprocess(cv2.imread(join(data_dir, ct_path.strip())))\n",
    "                steer = steer\n",
    "            elif camera == 'left':\n",
    "                frame = preprocess(cv2.imread(join(data_dir, lt_path.strip())))\n",
    "                steer = steer + delta_correction\n",
    "            elif camera == 'right':\n",
    "                frame = preprocess(cv2.imread(join(data_dir, rt_path.strip())))\n",
    "                steer = steer - delta_correction\n",
    "\n",
    "            if augment_data:\n",
    "\n",
    "                # mirror images with chance=0.5\n",
    "                if random.choice([True, False]):\n",
    "                    frame = frame[:, ::-1, :]\n",
    "                    steer *= -1.\n",
    "\n",
    "                # perturb slightly steering direction\n",
    "                steer += np.random.normal(loc=0, scale=CONFIG['augmentation_steer_sigma'])\n",
    "\n",
    "                # if color images, randomly change brightness\n",
    "                if CONFIG['input_channels'] == 3:\n",
    "                    frame = cv2.cvtColor(frame, code=cv2.COLOR_BGR2HSV)\n",
    "                    frame[:, :, 2] *= random.uniform(CONFIG['augmentation_value_min'], CONFIG['augmentation_value_max'])\n",
    "                    frame[:, :, 2] = np.clip(frame[:, :, 2], a_min=0, a_max=255)\n",
    "                    frame = cv2.cvtColor(frame, code=cv2.COLOR_HSV2BGR)\n",
    "\n",
    "            # check that each element in the batch meet the condition\n",
    "            steer_magnitude_thresh = np.random.rand()\n",
    "            if (abs(steer) + bias) < steer_magnitude_thresh:\n",
    "                pass  # discard this element\n",
    "            else:\n",
    "                X[loaded_elements] = frame\n",
    "                y_steer[loaded_elements] = steer\n",
    "                loaded_elements += 1\n",
    "\n",
    "        if K.backend() == 'theano':\n",
    "            X = X.transpose(0, 3, 1, 2)\n",
    "\n",
    "        yield X, y_steer\n",
    "\n",
    "        \n",
    "def get_nvidia_model(summary=True):\n",
    "    init = 'glorot_uniform'\n",
    "\n",
    "    if K.backend() == 'theano':\n",
    "        input_frame = Input(shape=(CONFIG['input_channels'], NVIDIA_H, NVIDIA_W))\n",
    "    else:\n",
    "        input_frame = Input(shape=(NVIDIA_H, NVIDIA_W, CONFIG['input_channels']))\n",
    "\n",
    "    # input normalization\n",
    "    x = Lambda(lambda z: z / 127.5 - 1.)(input_frame)\n",
    "\n",
    "    x = Convolution2D(24, 5, 5, border_mode='valid', subsample=(2, 2), init=init)(x)\n",
    "    x = ELU()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Convolution2D(36, 5, 5, border_mode='valid', subsample=(2, 2), init=init)(x)\n",
    "    x = ELU()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Convolution2D(48, 5, 5, border_mode='valid', subsample=(2, 2), init=init)(x)\n",
    "    x = ELU()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Convolution2D(64, 3, 3, border_mode='valid', init=init)(x)\n",
    "    x = ELU()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Convolution2D(64, 3, 3, border_mode='valid', init=init)(x)\n",
    "    x = ELU()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(100, init=init)(x)\n",
    "    x = ELU()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(50, init=init)(x)\n",
    "    x = ELU()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(10, init=init)(x)\n",
    "    x = ELU()(x)\n",
    "    out = Dense(1, init=init)(x)\n",
    "\n",
    "    model = Model(input=input_frame, output=out)\n",
    "\n",
    "    if summary:\n",
    "        model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def split_train_val(csv_driving_data):\n",
    "\n",
    "    with open(csv_driving_data, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        driving_data = [row for row in reader][1:]\n",
    "\n",
    "    train_data, val_data = train_test_split(driving_data, test_size=0.2, random_state=1)\n",
    "\n",
    "    return train_data, val_data\n",
    "\n",
    "### Main\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    train_data, val_data = split_train_val(csv_driving_data='data/driving_log.csv')\n",
    "    x_batch, y_batch = load_data_batch(train_data)\n",
    "    nvidia_net = get_nvidia_model(summary=True)\n",
    "    opt = Adam(lr=1e-3)\n",
    "    nvidia_net.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "    # json dump of model architecture\n",
    "    with open('logs/model.json', 'w') as f:\n",
    "        f.write(nvidia_net.to_json())\n",
    "\n",
    "    checkpointer = ModelCheckpoint('checkpoints/weights.{epoch:02d}-{val_loss:.3f}.hdf5')\n",
    "    logger = CSVLogger(filename='logs/history.csv')\n",
    "\n",
    "    nvidia_net.fit_generator(generator=generate_data_batch(train_data, augment_data=True, bias=CONFIG['bias']),\n",
    "                         samples_per_epoch=300*CONFIG['batchsize'],\n",
    "                         nb_epoch=50,\n",
    "                         validation_data=generate_data_batch(val_data, augment_data=False, bias=1.0),\n",
    "                         nb_val_samples=100*CONFIG['batchsize'],\n",
    "                         callbacks=[checkpointer, logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
